{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0b2ec2",
   "metadata": {},
   "source": [
    "### Fine tunning to follow instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6517829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data=file.read()\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b594c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f544afba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aab7f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \" \"\n",
    "    )\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95bd106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "719cb224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'? \n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd851587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length 935\n",
      "Validation set length 55\n",
      "Testing set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data)*0.85)\n",
    "test_portion = int(len(data)*0.1)\n",
    "val_portion = len(data) - test_portion - train_portion\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion+test_portion]\n",
    "val_data = data[train_portion+test_portion:]\n",
    "\n",
    "print(\"Training set length\", len(train_data))\n",
    "print(\"Validation set length\", len(val_data))\n",
    "print(\"Testing set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d738fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b7393e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd776d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_1st = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (new_item + [pad_token_id]* (batch_max_length - len(new_item)))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_1st.append(inputs)\n",
    "    inputs_tensor = torch.stack(inputs_1st).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "206b0541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0,1,2,3,4]\n",
    "inputs_2 = [5,6]\n",
    "inputs_3 = [ 7,8,9]\n",
    "batch= (inputs_1, inputs_2,inputs_3)\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed8e703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(batch, pad_token_id=50256, device = \"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_1st, targets_1st = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_1st.append(inputs)\n",
    "        targets_1st.append(targets)\n",
    "    inputs_tensor = torch.stack(inputs_1st).to(device)\n",
    "    targets_tensor = torch.stack(targets_1st).to(device)\n",
    "    return inputs_tensor,  targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "954760bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eb573ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch, pad_token_id =50256, ignore_index=-100, allowed_max_length = None, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_1st, targets_1st = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (new_item + [pad_token_id]* (batch_max_length - len(new_item)) )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel()>1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        inputs_1st.append(inputs)\n",
    "        targets_1st.append(targets)\n",
    "    inputs_tensor = torch.stack(inputs_1st).to(device)\n",
    "    targets_tensor = torch.stack(targets_1st).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31b0829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abe0a38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor([[-1.0, 1.0],[-0.5,1.5]])\n",
    "targets_1 = torch.tensor([0,1])\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f22e7ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor([[-1.0, 1.0],[-0.5,1.5], [-0.5,1.5]])\n",
    "targets_2 = torch.tensor([0,1,1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "639ad620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1==loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0,1,-100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2,targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1==loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fd7b843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "print(device)\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06553474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "custom_collate_fn = partial(custom_collate_fn, device = device, allowed_max_length =1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "788de932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "num_workers =0 \n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size= batch_size, collate_fn=custom_collate_fn, shuffle= True, num_workers=num_workers)\n",
    "val_dataset =InstructionDataset(val_data,tokenizer)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=custom_collate_fn,\n",
    "                        shuffle=False, drop_last= False,\n",
    "                        num_workers=num_workers)\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, \n",
    "                         collate_fn=custom_collate_fn, shuffle=False,\n",
    "                         drop_last=False,\n",
    "                         num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2a38251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 90]) torch.Size([8, 90])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 92]) torch.Size([8, 92])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 84]) torch.Size([8, 84])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([7, 72]) torch.Size([7, 72])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "431647c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from pretaining import GPTModel, load_weights_into_gpt\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\":1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\":768, \"n_layers\":12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\":1024, \"n_layers\":24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\":1280, \"n_layers\":36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\":1600, \"n_layers\":48, \"n_heads\": 25},\n",
    "}\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size= model_size,\n",
    "    models_dir= \"gpt2\"\n",
    ")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dc73efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.' \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4a1d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretaining import generate, text_to_token_ids, token_ids_to_text\n",
    "token_ids = generate(\n",
    "    model= model,\n",
    "    idx = text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85c70797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.' __________________________________________\n",
      "\n",
      "### Instruction\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b09d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing loss: 3.8171589374542236\n",
      "Validation loss: 3.76040997505188\n"
     ]
    }
   ],
   "source": [
    "from pretaining import (calc_loss_loader, train_model_simple)\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=5\n",
    "    )\n",
    "print(\"Traing loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d17957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step000000):Train loss 2.747,Val loss  2.717\n",
      "Ep 1 (Step000005):Train loss 1.229,Val loss  1.161\n",
      "Ep 1 (Step000010):Train loss 0.868,Val loss  0.957\n",
      "Ep 1 (Step000015):Train loss 0.859,Val loss  0.913\n",
      "Ep 1 (Step000020):Train loss 0.780,Val loss  0.881\n",
      "Ep 1 (Step000025):Train loss 0.744,Val loss  0.851\n",
      "Ep 1 (Step000030):Train loss 0.790,Val loss  0.831\n",
      "Ep 1 (Step000035):Train loss 0.714,Val loss  0.810\n",
      "Ep 1 (Step000040):Train loss 0.664,Val loss  0.800\n",
      "Ep 1 (Step000045):Train loss 0.632,Val loss  0.791\n",
      "Ep 1 (Step000050):Train loss 0.660,Val loss  0.781\n",
      "Ep 1 (Step000055):Train loss 0.758,Val loss  0.762\n",
      "Ep 1 (Step000060):Train loss 0.717,Val loss  0.741\n",
      "Ep 1 (Step000065):Train loss 0.649,Val loss  0.734\n",
      "Ep 1 (Step000070):Train loss 0.531,Val loss  0.728\n",
      "Ep 1 (Step000075):Train loss 0.568,Val loss  0.726\n",
      "Ep 1 (Step000080):Train loss 0.613,Val loss  0.726\n",
      "Ep 1 (Step000085):Train loss 0.506,Val loss  0.708\n",
      "Ep 1 (Step000090):Train loss 0.557,Val loss  0.689\n",
      "Ep 1 (Step000095):Train loss 0.497,Val loss  0.679\n",
      "Ep 1 (Step000100):Train loss 0.499,Val loss  0.669\n",
      "Ep 1 (Step000105):Train loss 0.567,Val loss  0.665\n",
      "Ep 1 (Step000110):Train loss 0.549,Val loss  0.661\n",
      "Ep 1 (Step000115):Train loss 0.506,Val loss  0.660\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step000120):Train loss 0.427,Val loss  0.666\n",
      "Ep 2 (Step000125):Train loss 0.445,Val loss  0.690\n",
      "Ep 2 (Step000130):Train loss 0.448,Val loss  0.686\n",
      "Ep 2 (Step000135):Train loss 0.406,Val loss  0.686\n",
      "Ep 2 (Step000140):Train loss 0.405,Val loss  0.683\n",
      "Ep 2 (Step000145):Train loss 0.369,Val loss  0.681\n",
      "Ep 2 (Step000150):Train loss 0.374,Val loss  0.674\n",
      "Ep 2 (Step000155):Train loss 0.410,Val loss  0.670\n",
      "Ep 2 (Step000160):Train loss 0.416,Val loss  0.672\n",
      "Ep 2 (Step000165):Train loss 0.372,Val loss  0.674\n",
      "Ep 2 (Step000170):Train loss 0.324,Val loss  0.675\n",
      "Ep 2 (Step000175):Train loss 0.334,Val loss  0.663\n",
      "Ep 2 (Step000180):Train loss 0.383,Val loss  0.647\n",
      "Ep 2 (Step000185):Train loss 0.406,Val loss  0.649\n",
      "Ep 2 (Step000190):Train loss 0.336,Val loss  0.641\n",
      "Ep 2 (Step000195):Train loss 0.323,Val loss  0.627\n",
      "Ep 2 (Step000200):Train loss 0.301,Val loss  0.626\n",
      "Ep 2 (Step000205):Train loss 0.342,Val loss  0.624\n",
      "Ep 2 (Step000210):Train loss 0.358,Val loss  0.622\n",
      "Ep 2 (Step000215):Train loss 0.386,Val loss  0.627\n",
      "Ep 2 (Step000220):Train loss 0.294,Val loss  0.638\n",
      "Ep 2 (Step000225):Train loss 0.346,Val loss  0.653\n",
      "Ep 2 (Step000230):Train loss 0.287,Val loss  0.650\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in  15.44 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr =0.00005, weight_decay=0.1)\n",
    "num_epochs =2\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device, num_epochs=num_epochs,\n",
    "    eval_freq=5, eval_iter=5, \n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time -start_time)/60\n",
    "print(f\"Training completed in {execution_time_minutes: .2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da4b77f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pretaining import plot_losses\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses,val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ed0d67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> ### Response:\n",
      "The car is as fast as a cheetah.\n",
      "---------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms? \n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> ### Response:\n",
      "A thunderstorm is a type of cloud that typically forms when thunderstorms are active.\n",
      "---------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'. \n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> ### Response:\n",
      "The author of 'Pride and Prejudice' is Jane Austen.\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(model=model, \n",
    "                         idx = text_to_token_ids(input_text, tokenizer).to(device),\n",
    "                         max_new_tokens=256,\n",
    "                         context_size=BASE_CONFIG[\"context_length\"],\n",
    "                         eos_id=50256)\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"###Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c4bff07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 110/110 [05:23<00:00,  2.94s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx = text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"###Response:\",\"\")\n",
    "        .strip()\n",
    "    )\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent =4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3230eba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': '### Response:\\nThe car is as fast as a cheetah.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e87a224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M)-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "file_name = f\"{re.sub(r' [ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c839e8f4",
   "metadata": {},
   "source": [
    "### Evaluating the fine-tuned LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8111046d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\n",
    "        \"Ollama not working.Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "46f68c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "def query_model(prompt, model = \"llama3\",url = \"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [ {\"role\": \"user\", \"content\": prompt}],\n",
    "        \"options\": {\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\":2048\n",
    "        }\n",
    "    }\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(\n",
    "        url, data= payload,\n",
    "        method = \"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True: \n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "    return response_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "19be6761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
      "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
      "4. Fruits and vegetables: Fresh fruits and veggies, such as apples, carrots, and sweet potatoes, are a tasty treat for llamas. They're also a good source of fiber, vitamins, and minerals.\n",
      "5. Minerals: Llamas need access to mineral supplements, like salt licks or loose minerals, to ensure they receive the necessary nutrients.\n",
      "\n",
      "In general, a llama's diet should consist of:\n",
      "\n",
      "* 70-80% hay (high-quality grass hay or alfalfa)\n",
      "* 10-20% grains (oats, barley, or corn)\n",
      "* 5-10% fruits and vegetables\n",
      "* 1-2% minerals (salt licks or loose minerals)\n",
      "\n",
      "It's crucial to provide a balanced diet for llamas, as they can be prone to digestive issues if their nutritional needs aren't met. Consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3\"\n",
    "result = query_model(\"What do llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "46531119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> ### Response:\n",
      "The car is as fast as a cheetah.\n",
      "\n",
      "Score:\n",
      ">> To score this model response, I'll compare it to the expected output.\n",
      "\n",
      "Expected output: The car is as fast as lightning.\n",
      "Model response: The car is as fast as a cheetah.\n",
      "\n",
      "Similarity: Both responses use a simile (\"as X as Y\") and both comparisons are related to speed (lightning is extremely fast, and a cheetah is very fast). However, the expected output uses a more extreme example of speed (lightning) to emphasize just how fast the car is, whereas the model response uses a slightly less extreme example (a cheetah).\n",
      "\n",
      "Score: 85\n",
      "\n",
      "The model response is close to the expected output, but it's not quite as effective at conveying the idea that the car is extremely fast.\n",
      "\n",
      "---------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> ### Response:\n",
      "A thunderstorm is a type of cloud that typically forms when thunderstorms are active.\n",
      "\n",
      "Score:\n",
      ">> I'd rate this model response as a 20 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The response doesn't directly answer the question about what type of cloud is typically associated with thunderstorms.\n",
      "* Instead, it describes thunderstorms themselves, which is not relevant to the original question.\n",
      "* The response also contains some ambiguity and unclear language (\"A thunderstorm is a type of cloud...\"), which makes it difficult to understand.\n",
      "\n",
      "To improve this response, I would suggest rewriting it to directly answer the question. For example:\n",
      "\n",
      "### Response:\n",
      "The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "This revised response accurately answers the original question and provides a clear and concise answer.\n",
      "\n",
      "---------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> ### Response:\n",
      "The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> ### Response:\n",
      "The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "### Score: 100\n",
      "\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}`\"\n",
    "        f\"and correct output `{entry['output']}`,\"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\"on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f50fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_modle_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc = \"Scoring entries\"):\n",
    "        prompt = (\n",
    "        f\"Given the input `{format_input(entry)}`\"\n",
    "        f\"and correct output `{entry['output']}`,\"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\"on a scale from 0 to 100, where 100 is the best score. \"\n",
    "        f\"Respond with the integer number only.\"\n",
    "    )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3ecb0106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|| 110/110 [00:54<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score:  54.04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = generate_modle_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: { len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: { sum(scores)/ len(scores): .2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9b903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57620255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f24728b1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
